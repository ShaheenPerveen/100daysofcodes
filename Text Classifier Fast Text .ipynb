{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classifier \n",
    "\n",
    "### Author: Ayushman Gupta\n",
    "\n",
    "<b> Word Embeddin:</b> Fast Text <br/>\n",
    "<b>Model:</b> Neural Network <br/>\n",
    "<b> Datasets :</b> Made up <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('desks', 0.7923153638839722), ('Desk', 0.6869950890541077), ('desk.', 0.6602819561958313), ('desk-', 0.6187258958816528), ('credenza', 0.595531702041626), ('roll-top', 0.5875717401504517), ('rolltop', 0.5837830305099487), ('bookshelf', 0.5758029818534851), ('Desks', 0.5755287408828735), ('sofa', 0.5617446899414062)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')\n",
    "print (model.most_similar('desk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vocab = []\n",
    "for word in model.vocab:\n",
    "    my_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size 999994\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab Size {}\".format(len(my_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['this', 'is', 'the', 'good', 'machine', 'learning', 'book'],\n",
    "            ['this', 'is',  'another', 'machine', 'learning', 'book'],\n",
    "            ['one', 'more', 'new', 'book'],\n",
    "         \n",
    "          ['this', 'is', 'about', 'machine', 'learning', 'post'],\n",
    "          ['orange', 'juice', 'is', 'the', 'liquid', 'extract', 'of', 'fruit'],\n",
    "          ['orange', 'juice', 'comes', 'in', 'several', 'different', 'varieties'],\n",
    "          ['this', 'is', 'the', 'last', 'machine', 'learning', 'book'],\n",
    "          ['orange', 'juice', 'comes', 'in', 'several', 'different', 'packages'],\n",
    "          ['orange', 'juice', 'is', 'liquid', 'extract', 'from', 'fruit', 'on', 'orange', 'tree']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vectorizing sentence \n",
    "\n",
    "def sentence_vetorizer(sentence,model):\n",
    "    vec =[]\n",
    "    numw = 0\n",
    "    try:\n",
    "        \n",
    "        for w in sentence:\n",
    "            if numw == 0:\n",
    "                vec = model[w]\n",
    "\n",
    "            else:\n",
    "                vec = np.add(vec,model[w])\n",
    "            numw +=1\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return np.asarray(vec)/numw #mormlizing vectors\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating vectors for all sentences\n",
    "\n",
    "main_vec = []\n",
    "for sent in sentences:\n",
    "    \n",
    "    main_vec.append(sentence_vetorizer(sent,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test data\n",
    "\n",
    "X_train = main_vec[0:6]\n",
    "X_test = main_vec[6:9] \n",
    "Y_train = [0, 0, 0, 0, 1,1]\n",
    "Y_test =  [0,1,1]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Neural Network\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(alpha=.7, max_iter=400)\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trian fit score\n",
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# testing fit score\n",
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
